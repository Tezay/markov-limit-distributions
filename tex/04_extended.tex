\section*{Pour aller plus loin}
\phantomsection
\addcontentsline{toc}{section}{Pour aller plus loin}

\subsection*{Question 11 — Combinaison linéaire des distributions limites depuis l’état 14}
\phantomsection
\addcontentsline{toc}{subsection}{Question 11 — Combinaison linéaire des distributions limites depuis l’état 14}

Comme vu précédemment, l’état \(14\) appartient à la classe \(C_6\), qui est transitoire vers les classes \(C_5\) et \(C_2\).  
Il a une connexion directe avec les états \(2\) et \(8\), donc \(14\) est un état transitoire vers \(C_5\) et \(C_2\).

L’état \(2\) appartient à la classe \(C_2\) et l’état \(8\) appartient à la classe \(C_5\), qui sont toutes deux des classes finales.

Nous cherchons à prouver que la distribution limite \(L\Pi_C\) partant de l’état \(14\) est une combinaison linéaire des distributions limites \(L\Pi_A\) et \(L\Pi_B\) partant respectivement des états \(2\) et \(8\).

\[
\exists (\alpha,\beta) \in \mathbb{R}^2,\quad L\Pi_C = \alpha\,L\Pi_A + \beta\,L\Pi_B.
\]

Nous pouvons donc interpréter les coefficients \(\alpha\) et \(\beta\) comme les probabilités d’atteindre les
classes \(C_5\) et \(C_2\) en partant de l’état \(14\).  
Sachant cela, \(14\) doit nécessairement atteindre la classe \(C_5\) ou \(C_2\), on peut donc en déduire
que :
\[
\alpha + \beta = 1 \quad \text{(somme des probabilités).}
\]

En reprenant l’équation fondamentale qui décrit la dynamique d’une chaîne de Markov.  
Nous définissons :
\[
x_i = P(\text{Atteindre } C_2 \mid X_0 = i),
\qquad
x_j = P(\text{Atteindre } C_2 \mid X_1 = j),
\]
qui découle de l'application de la Formule des Probabilités Totales sur le premier pas de transition.

\bigskip

\textbf{Rappel :} nous pouvons utiliser le premier pas pour par la suite exprimer les limites grâce à  
l'homogénéité temporelle : les probabilités de transition pour passer d’un état à un autre en un  
pas sont indépendantes du temps (1.2 4) du sujet).

Nous avons donc l’équation suivante :
\[
x_i = \sum_{j=1}^{27} P(X_1 = j \mid X_0 = i) * x_j
\]

On simplifie :
\[
x_i = \sum_{j=1}^{27} P_{ij} * x_j
\]

\bigskip

En appliquant cela à \(i=14\), et comme \(\alpha = x_{14}\), on obtient :

\[
x_{14} = \alpha
= P_{14,14} \cdot \alpha
+ \sum_{j \in C_2} P_{14,j} \cdot 1
+ \sum_{j \in C_5} P_{14,j} \cdot 0.
\]

C’est-à-dire :
\[
\alpha = P_{14,14}\alpha + \sum_{j\in C_2} P_{14,j}.
\]

\bigskip

\textbf{En isolant \(\alpha\) :}
\[
\alpha - P_{14,14}\alpha = \sum_{j\in C_2} P_{14,j}
\quad\Longleftrightarrow\quad
\alpha (1 - P_{14,14}) = \sum_{j\in C_2} P_{14,j}
\quad\Longleftrightarrow\quad
\alpha = \frac{\displaystyle\sum_{j\in C_2} P_{14,j}}{1 - P_{14,14}}.
\]

\bigskip

On sait que \(P_{14,14} = 0.4\).

De plus :
\[
\sum_{j\in C_2} P_{14,j}
= P_{14,5} + P_{14,12} + P_{14,21} + P_{14,25} + P_{14,2}.
\]

Comme l’état \(14\) ne pointe directement que vers \(2\) et \(5\) :
\[
\sum_{j\in C_2} P_{14,j}
= P_{14,5} + P_{14,2}
= 0.1 + 0.2
= 0.3.
\]

Ainsi :
\[
\alpha = \frac{0.3}{1 - 0.4}
       = \frac{0.3}{0.6}
       = \frac12.
\]

Comme \(\alpha + \beta = 1\), on obtient :
\[
\beta = 1 - \alpha = \frac12.
\]

\[
\boxed{
L\Pi_C = \frac12 L\Pi_A + \frac12 L\Pi_B.
}
\]

\textbf{Conclusion :} la distribution limite issue de l’état \(14\) est égale à la combinaison linéaire à poids égaux des distributions limites issues de \(2\) et \(8\).



\subsection*{Question 12 — probabilités d'atteindre les classes finales}
\phantomsection
\addcontentsline{toc}{subsection}{Question 12 — probabilités d'atteindre les classes finales}
Nous cherchons à déterminer la probabilité d'absorption dans les classes finales \(C_2\) et \(C_5\) en partant des états transitoires \(s \in \{10, 19, 22, 24\}\).
On note \(x_i = P(i \to C_2)\) la probabilité d'atteindre la classe \(C_2\) partant de l'état \(i\).
Puisque les seules classes finales accessibles sont \(C_2\) et \(C_5\), on aura \(P(i \to C_5) = 1 - x_i\).

\paragraph{1. Calcul théorique (Estimation à la main)}

Nous savons d'après la question 11 que pour l'état 14 (classe \(C_6\)), qui mène vers \(C_2\) et \(C_5\) :
\[ x_{14} = P(14 \to C_2) = 0.5 \]

Pour les états de la classe \(C_7\) (\(10, 19, 22, 24\)), nous écrivons le système d'équations linéaires basé sur les transitions en un seul pas, pour arriver jusqu'à \(C_2\) (puis on obtiendra pour \(C_5\) en faisant \(1 - x_i\)) :
\[
\begin{cases}
    x_{10} = 0.4 + 0.2 x_{19} + 0.2 x_{22} + 0.2 x_{24} & (1) \\
    x_{19} = 0.1 x_{10} + 0.5 x_{19} + 0.1 x_{22} + 0.3 x_{24} & (2) \\
    x_{22} = 0.2 x_{10} + 0.2 x_{19} + 0.2 x_{24} & (3) \\
    x_{24} = 0.3 x_{10} + 0.1 x_{14} + 0.3 x_{19} + 0.3 x_{22} & (4)
\end{cases}
\]

\textbf{Résolution :}
En soustrayant l'équation (3) à l'équation (1) on obtient :
\[ x_{10} - x_{22} = 0.4 + 0.2 x_{22} - 0.2 x_{10} \iff 1.2 x_{10} - 1.2 x_{22} = 0.4 \iff x_{10} = x_{22} + \frac{1}{3} \]

En injectant cette relation dans (3) on trouve :
\[ x_{22} = 0.2(x_{22} + \frac{1}{3}) + 0.2 x_{19} + 0.2 x_{24} \]
En utilisant (2) et (4) et en sachant que \(x_{14} = \frac{1}{2}\), la résolution du système donne les valeurs suivantes pour atteindre la classe \(C_2\) :
\[
x_{10} = \frac{2}{3}, \quad
x_{19} = \frac{1}{2}, \quad
x_{22} = \frac{1}{3}, \quad
x_{24} = \frac{1}{2}.
\]

Ensuite, les probabilités d'atteindre \(C_5\) sont les compléments à 1 (car il n'y a que \(C_2\) et \(C_5\) comme classes finales accessibles depuis \(C_7\)) :
\[
P(10 \to C_5) = 1/3, \quad
P(19 \to C_5) = 1/2, \quad
P(22 \to C_5) = 2/3, \quad
P(24 \to C_5) = 1/2
\]

Et donc les autres classes finales \(C_1\) et \(C_3\) sont atteintes avec une probabilité de 0 (car pas reliées à \(C_7\)).

\paragraph{2. Valeur "exacte" par l'ordinateur}

Nous avons exécuté le programme \texttt{markov\_analyzer} pour chacun de ces états de départ avec \(n=100\) étapes. Les commandes utilisées sont :
\begin{verbatim}
./markov_analyzer --in data/moodle/matrix.txt --dist-start 10 --dist-steps 100
./markov_analyzer --in data/moodle/matrix.txt --dist-start 19 --dist-steps 100
./markov_analyzer --in data/moodle/matrix.txt --dist-start 22 --dist-steps 100
./markov_analyzer --in data/moodle/matrix.txt --dist-start 24 --dist-steps 100
\end{verbatim}

Les résultats sont extraits de la ligne \texttt{[Distribution]} des fichiers de sortie (\texttt{data/q12/sim\_*.txt}), qui donne le vecteur \(\Pi^{(100)}\).
Pour obtenir la probabilité d'absorption dans une classe, nous faisons la somme des probabilités des états appartenant à cette classe :
\begin{itemize}
    \item Pour \(C_2 = \{2, 5, 12, 21, 25\}\) : on somme les composantes aux indices 2, 5, 12, 21 et 25.
    \item Pour \(C_5 = \{8, 9, 16\}\) : on somme les composantes aux indices 8, 9 et 16.
\end{itemize}

Les résultats numériques obtenus sont :

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        État de départ \(s\) & 10 & 19 & 22 & 24 \\
        \midrule
        \textbf{Calcul théorique} \(P(s \to C_2)\) & \textbf{0.6667} & \textbf{0.5000} & \textbf{0.3333} & \textbf{0.5000} \\
        Simulation \(\sum_{j \in C_2} \Pi^{(100)}(j)\) & 0.6667 & 0.5000 & 0.3333 & 0.5000 \\
        \midrule
        \textbf{Calcul théorique} \(P(s \to C_5)\) & \textbf{0.3333} & \textbf{0.5000} & \textbf{0.6667} & \textbf{0.5000} \\
        Simulation \(\sum_{j \in C_5} \Pi^{(100)}(j)\) & 0.3333 & 0.5000 & 0.6667 & 0.5000 \\
        \bottomrule
    \end{tabular}
    \caption{Comparaison des probabilités d'absorption théoriques et simulées.}
    \label{tab:q12_absorption}
\end{table}

\textbf{Conclusion :} Les valeurs simulées par l'ordinateur correspondent parfaitement aux valeurs théoriques calculées par résolution du système linéaire. Cela confirme la cohérence de notre modèle et de l'implémentation.

\subsection*{Question 13 : Preuve de l'Égalité des Périodes dans une Classe Communicante}
\phantomsection
\addcontentsline{toc}{subsection}{Question 13 : Preuve de l'Égalité des Périodes dans une Classe Communicante}

\paragraph{Définitions Préalables}

\begin{itemize}[label=$\diamond$]
    \item \textbf{Communication :} Deux états $i$ et $j$ communiquent ($i \longleftrightarrow j$) s'il existe $m \geq 1$ et $k \geq 1$ tels que la probabilité de transition $P_{ij}^{(m)} > 0$ et $P_{ji}^{(k)} > 0$.
    \item \textbf{Période :} La période d'un état $i$, notée $d(i)$, est le plus grand commun diviseur (pgcd) des longueurs de tous les chemins partant de $i$ et y retournant :
    $$d(i) = \text{pgcd} \{n \geq 1 \mid P_{ii}^{(n)} > 0 \}$$
\end{itemize}

\paragraph{Preuve}
Soient $i$ et $j$ deux états de la même classe communicante.
Il existe des chemins :
\begin{itemize}
    \item $i \to j$ de longueur $m$.
    \item $j \to i$ de longueur $k$.
\end{itemize}

Soit $n$ une longueur quelconque d'un chemin de retour pour l'état $j$, i.e., $P_{jj}^{(n)} > 0$. Par définition, $d(j) \mid n$.

Considérons le chemin composite de $i$ à $i$ passant par $j$ :
$$i \xrightarrow{m} j \xrightarrow{n} j \xrightarrow{k} i$$
La longueur totale est $\ell_1 = m + n + k$.
Puisque $P_{ii}^{(m+n+k)} \geq P_{ij}^{(m)} P_{jj}^{(n)} P_{ji}^{(k)} > 0$, $\ell_1$ est une longueur de retour valide pour l'état $i$.

Considérons également le chemin de retour simple :
$$i \xrightarrow{m} j \xrightarrow{k} i$$
La longueur totale est $\ell_2 = m + k$.
Puisque $P_{ii}^{(m+k)} \geq P_{ij}^{(m)} P_{ji}^{(k)} > 0$, $\ell_2$ est une longueur de retour valide pour l'état $i$.

Par définition de $d(i)$, celui-ci doit diviser toutes les longueurs de retour valides, y compris $\ell_1$ et $\ell_2$ :
$$ d(i) \mid (m + n + k) \quad (E1)$$
$$ d(i) \mid (m + k) \quad (E2)$$

En soustrayant $(E1)$ de $(E2)$ (propriété de divisibilité), nous obtenons :
$$d(i) \mid [(m + n + k) - (m + k)]$$
$$d(i) \mid n$$
Cette relation est vraie pour tout $n$ tel que $P_{jj}^{(n)} > 0$. Par conséquent, $d(i)$ divise tous les éléments de l'ensemble dont $d(j)$ est le PGCD. On en déduit :
$$ d(i) \mid d(j) \quad (E3)$$

On peut échanger $$d(j)$$ et $$d(i)$$ et ainsi, on obtient :
$$ d(j) \mid d(i) \quad (E4)$$

Puisque $d(i)$ et $d(j)$ sont des entiers positifs qui se divisent mutuellement, on conclut que :
$$d(i) = d(j)$$
Donc deux états appartenant à la même classe communicante ont nécessairement la même période.



\subsection*{Question 14 : Le nombre de distributions limite}
\phantomsection
\addcontentsline{toc}{subsection}{Question 14 : Le nombre de distributions limite}

Soient $L$ l'ensemble des distributions limites et $S$ l'ensemble des distributions stationnaires d'une chaîne de Markov finie de matrice de transition $P$.

\subsubsection*{a) Montrer que si $\pi$ est un vecteur stationnaire de $P$, alors pour tout $k \geq 0$, $\pi = \pi P^k$.}

\begin{proof}
Par définition, $\pi$ est stationnaire si $\pi = \pi P$.
\begin{itemize}
    \item \textbf{Cas de base ($k=0$) :} $\pi P^0 = \pi I = \pi$.
    \item \textbf{Cas $k=1$} : $\pi P^1 = \pi P = \pi$.
    \item \textbf{Preuve par récurrence :} Supposons que $\pi = \pi P^k$ pour un certain $k \geq 1$. Alors pour $k+1$ :
    $$
    \pi P^{k+1} = \pi (P^k P) = (\pi P^k) P
    $$
    En utilisant l'hypothèse de récurrence ($\pi P^k = \pi$) :
    $$
    \pi P^{k+1} = \pi P = \pi
    $$
\end{itemize}
La propriété est vérifiée pour tout $k \geq 0$.
\end{proof}

\subsubsection*{b) Prouver que $L = S$.}

\begin{proof}
Nous démontrons la double inclusion.

\textbf{1. $L \subset S$ (Toute distribution limite est stationnaire) :}
Soit $\pi \in L$. Il existe une distribution initiale $\Pi(0)$ telle que $\pi = \lim_{n\rightarrow+\infty} \Pi(0) P^n$.
$$
\pi P = \left( \lim_{n\rightarrow+\infty} \Pi(0) P^n \right) P = \lim_{n\rightarrow+\infty} \Pi(0) P^{n+1} = \pi
$$
Donc $\pi$ vérifie $\pi = \pi P$, ce qui signifie $\pi \in S$.

\textbf{2. $S \subset L$ (Toute distribution stationnaire est limite) :}
Soit $\pi \in S$. D'après la question 14.a), nous savons que $\pi P^k = \pi$ pour tout $k \geq 0$.
En choisissant la distribution initiale $\Pi(0) = \pi$, la limite est :
$$
\lim_{k\rightarrow+\infty} \Pi(0) P^k = \lim_{k\rightarrow+\infty} \pi P^k = \lim_{k\rightarrow+\infty} \pi = \pi
$$
Donc $\pi \in L$.
Puisque $L \subset S$ et $S \subset L$, nous concluons que $L = S$.
\end{proof}

\subsubsection*{c) Propriétés de $L$ et $S$.}

\textbf{i) $S$ n'est pas un sous-espace vectoriel de $\mathbb{R}^n$}

\begin{proof}
Un vecteur stationnaire $\pi$ est une distribution de probabilité, donc la somme de ses composantes est égale à 1 : $\sum_{i} \pi_i = 1$.
Le vecteur nul $\mathbf{0}$ ne vérifie pas cette condition puisque $\sum_{i} \mathbf{0}_i = 0 \neq 1$.
Puisque $S$ ne contient pas l'élément neutre de l'addition vectorielle, $\mathbf{0} \notin S$.
Donc $S$ n'est pas un sous-espace vectoriel de $\mathbb{R}^n$.
\end{proof}

\textbf{ii) $S$ est un sous-ensemble convexe.}

\begin{proof}
Soient $\pi_1, \pi_2 \in S$ et $\alpha \in [0, 1]$. Considérons $\pi_{\alpha} = \alpha \pi_1 + (1-\alpha) \pi_2$.
\begin{itemize}
    \item $\pi_{\alpha}$ est une distribution de probabilité : $\sum_{i} \pi_{\alpha, i} = \alpha \sum_{i} \pi_{1, i} + (1-\alpha) \sum_{i} \pi_{2, i} = \alpha(1) + (1-\alpha)(1) = 1$.
    \item $\pi_{\alpha}$ est stationnaire :
    $$
    \pi_{\alpha} P = (\alpha \pi_1 + (1-\alpha) \pi_2) P = \alpha (\pi_1 P) + (1-\alpha) (\pi_2 P)
    $$
    Puisque $\pi_1, \pi_2 \in S$, $\pi_1 P = \pi_1$ et $\pi_2 P = \pi_2$.
    $$
    \pi_{\alpha} P = \alpha \pi_1 + (1-\alpha) \pi_2 = \pi_{\alpha}
    $$
\end{itemize}
Puisque $\pi_{\alpha} \in S$, $S$ est un sous-ensemble convexe.
\end{proof}

\subsubsection*{d) Prouver que toute chaîne de Markov finie admet au moins une distribution stationnaire.}

\begin{proof}
L'équation d'invariance $\pi = \pi P$ est équivalente à $\pi (P - I) = \mathbf{0}$. L'existence d'une solution non nulle $\pi$ est garantie si $\det(P - I) = 0$, c'est-à-dire si $\lambda=1$ est une valeur propre de $P$.

1.  La matrice de transition $P$ est une \textbf{matrice stochastique} (la somme de chaque ligne est 1).
2.  Considérons le vecteur colonne $\mathbf{1} = (1, 1, \dots, 1)^T$.
3.  La matrice transposée $P^T$ a pour propriété que la somme de ses colonnes est 1.
4.  Le produit $P^T \mathbf{1}$ donne un vecteur colonne dont chaque composante est la somme d'une colonne de $P^T$, soit une ligne de $P$, qui est 1.
    $$
    P^T \mathbf{1} = \mathbf{1}
    $$
    Ceci montre que $\mathbf{1}$ est un vecteur propre à droite de $P^T$ associé à la valeur propre $\lambda=1$.
5.  Puisque $\det(A) = \det(A^T)$, les matrices $P$ et $P^T$ ont les mêmes valeurs propres. Donc $\lambda=1$ est aussi une valeur propre de $P$.
6.  L'espace propre à gauche associé à 1, $\ker(P-I)$, est non trivial. Il contient un vecteur $\pi$ non nul qui peut être normalisé pour obtenir une distribution de probabilité.
\end{proof}

\subsubsection*{e) Montrer qu'une chaîne de Markov réductible admet une infinité de distributions limite.}

\begin{proof}
Une chaîne de Markov réductible, pourvu qu'elle ait au moins deux classes communicantes finales distinctes, $C_1$ et $C_2$, admet des distributions stationnaires $\pi_1$ et $\pi_2$ dont les supports sont disjoints.

1.  L'existence de $\pi_1$ et $\pi_2$ est garantie par la question 14.d) appliquée aux sous-matrices de transition restreintes à chaque classe finale.
2.  $\pi_1$ et $\pi_2$ sont des éléments distincts de l'ensemble $S$.
3.  D'après la question 14.c), $S$ est un ensemble \textbf{convexe}.
4.  Toute combinaison convexe $\pi_{\alpha} = \alpha \pi_1 + (1-\alpha) \pi_2$ avec $\alpha \in [0, 1]$ est également une distribution stationnaire ($\pi_{\alpha} \in S$).
Puisque l'intervalle $[0, 1]$ contient une infinité de valeurs réelles distinctes, il existe une infinité de distributions stationnaires. Comme $L=S$, la chaîne admet une infinité de distributions limites.
\end{proof}

\subsubsection*{f) Montrer qu'une chaîne irréductible et $d$-périodique $(d \neq 1)$ n'admet pas toujours de distribution limite.}

\begin{proof}
Considérons la chaîne de Markov irréductible et 2-périodique ($d=2$) correspondant au cycle déterministe entre deux états (1 et 2) :
$$
P = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}
$$
La suite des matrices de transition $(P^n)$ est oscillante : $P^{2k} = I$ et $P^{2k+1} = P$. Elle ne converge pas.

Soit la distribution initiale $\Pi(0) = (1, 0)$ (commence en état 1). La séquence de distributions est :
\begin{align*}
\Pi(2k) &= \Pi(0) P^{2k} = (1, 0) I = (1, 0) \\
\Pi(2k+1) &= \Pi(0) P^{2k+1} = (1, 0) P = (0, 1)
\end{align*}
La suite $\Pi(n)$ alterne indéfiniment entre $(1, 0)$ et $(0, 1)$. Par définition, la limite $\lim_{n\rightarrow+\infty} \Pi(n)$ n'existe pas.
Ainsi, une chaîne de Markov irréductible et $d$-périodique ($d \neq 1$) n'admet pas toujours de distribution limite.
\end{proof}